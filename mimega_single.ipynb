{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "2846fdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, BatchNorm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from torch_geometric.data import Dataset, Data\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "e9720f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametri di clustering\n",
    "CLUSTER_PARAMS = dict(\n",
    "    charge_threshold=750,\n",
    "    min_consecutive_strips=2,\n",
    "    max_gap=2,\n",
    "    max_cluster_size=15,\n",
    "    max_internal_gap=2\n",
    ")\n",
    "\n",
    "def cluster_strips_with_charges(event, params):\n",
    "    clusters = []\n",
    "    charges = []\n",
    "    current_cluster = []\n",
    "    current_charges = []\n",
    "    previous_index = None\n",
    "    for strip_index, charge in enumerate(event):\n",
    "        if charge >= params['charge_threshold']:\n",
    "            if previous_index is not None and strip_index - previous_index - 1 >= params['max_gap']:\n",
    "                if params['min_consecutive_strips'] <= len(current_cluster) < params['max_cluster_size']:\n",
    "                    n_gaps = (max(current_cluster) - min(current_cluster) + 1) - len(current_cluster)\n",
    "                    if n_gaps <= params['max_internal_gap']:\n",
    "                        clusters.append(current_cluster)\n",
    "                        charges.append(current_charges)\n",
    "                current_cluster = []\n",
    "                current_charges = []\n",
    "            current_cluster.append(strip_index)\n",
    "            current_charges.append(charge)\n",
    "            previous_index = strip_index\n",
    "        else:\n",
    "            continue\n",
    "    # Chiudi eventuale cluster rimasto\n",
    "    if params['min_consecutive_strips'] <= len(current_cluster) < params['max_cluster_size']:\n",
    "        n_gaps = (max(current_cluster) - min(current_cluster) + 1) - len(current_cluster)\n",
    "        if n_gaps <= params['max_internal_gap']:\n",
    "            clusters.append(current_cluster)\n",
    "            charges.append(current_charges)\n",
    "    return clusters, charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "96860ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di cluster trovati in X: 908\n",
      "Numero di cluster trovati in Y: 3047\n"
     ]
    }
   ],
   "source": [
    "# Carica i dati\n",
    "x_events = np.load('data/2/test_x.npy', allow_pickle=True)\n",
    "y_events = np.load('data/2/test_y.npy', allow_pickle=True)\n",
    "\n",
    "def assign_labels(event, params):\n",
    "    labels = np.zeros(len(event), dtype=int)\n",
    "    clusters, _ = cluster_strips_with_charges(event, params)\n",
    "    for i, cluster in enumerate(clusters):\n",
    "        for idx in range(min(cluster), max(cluster) + 1):\n",
    "            labels[idx] = 1\n",
    "    return labels, len(clusters)\n",
    "\n",
    "# Esempio: genera labels per tutti gli eventi X e Y e stampa il numero di cluster trovati\n",
    "x_labels = []\n",
    "y_labels = []\n",
    "n_x_clusters = 0\n",
    "n_y_clusters = 0\n",
    "max_label = 0\n",
    "for i in range(len(x_events)):\n",
    "    \n",
    "    x_label_temp, n_x_clusters_temp = assign_labels(x_events[i], CLUSTER_PARAMS)\n",
    "    x_labels.append(x_label_temp)\n",
    "    n_x_clusters+=(n_x_clusters_temp)\n",
    "\n",
    "    y_labels_temp, n_y_clusters_temp = assign_labels(y_events[i], CLUSTER_PARAMS)\n",
    "    y_labels.append(y_labels_temp)\n",
    "    n_y_clusters+=(n_y_clusters_temp)\n",
    "\n",
    "print(f\"Numero di cluster trovati in X: {n_x_clusters}\")\n",
    "print(f\"Numero di cluster trovati in Y: {n_y_clusters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "09010b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unisci gli eventi x e y per formare all_events e all_labels\n",
    "all_events = np.concatenate([x_events, y_events], axis=0)\n",
    "all_labels = np.concatenate([x_labels, y_labels], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "5630a51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def events_to_graphs(events, labels):\n",
    "    data_list = []\n",
    "    for event, label in zip(events, labels):\n",
    "        event = np.array(event, dtype=np.float32)\n",
    "        label = np.array(label, dtype=np.int64)\n",
    "        x = torch.tensor(event, dtype=torch.float).unsqueeze(1)\n",
    "        y = torch.tensor(label, dtype=torch.long)\n",
    "        N = x.shape[0]\n",
    "        edge_index = torch.tensor(\n",
    "            [[i, i+1] for i in range(N-1)] + [[i+1, i] for i in range(N-1)],\n",
    "            dtype=torch.long\n",
    "        ).t().contiguous()\n",
    "        data = Data(x=x, edge_index=edge_index, y=y)\n",
    "        data_list.append(data)\n",
    "    return data_list\n",
    "\n",
    "# Unisci eventi e label in una lista di tuple\n",
    "all_data = list(zip(all_events, all_labels))\n",
    "\n",
    "# Split: 70% train, 15% val, 15% test\n",
    "train_data, temp_data = train_test_split(all_data, test_size=0.3, random_state=42, shuffle=True)\n",
    "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42, shuffle=True)\n",
    "\n",
    "# Estrai eventi e label per ogni split\n",
    "train_events, train_labels = zip(*train_data)\n",
    "val_events, val_labels = zip(*val_data)\n",
    "test_events, test_labels = zip(*test_data)\n",
    "\n",
    "# Crea i dataset come liste di Data\n",
    "train_graphs = events_to_graphs(train_events, train_labels)\n",
    "val_graphs = events_to_graphs(val_events, val_labels)\n",
    "test_graphs = events_to_graphs(test_events, test_labels)\n",
    "\n",
    "# DataLoader PyG\n",
    "from torch_geometric.loader import DataLoader\n",
    "train_loader = DataLoader(train_graphs, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_graphs, batch_size=32)\n",
    "test_loader = DataLoader(test_graphs, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "036f3f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "pos_weight for BCEWithLogitsLoss: 16.82\n"
     ]
    }
   ],
   "source": [
    "# Modello GNN per la segmentazione strip-wise con dropout e blocchi ripetibili\n",
    "class StripGCN(nn.Module):\n",
    "    def __init__(self, in_channels=1, hidden_channels=32, num_layers=3, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.bns = nn.ModuleList()\n",
    "        # Primo layer\n",
    "        self.convs.append(GCNConv(in_channels, hidden_channels))\n",
    "        self.bns.append(BatchNorm(hidden_channels))\n",
    "        # Layer intermedi\n",
    "        for _ in range(num_layers-1):\n",
    "            self.convs.append(GCNConv(hidden_channels, hidden_channels))\n",
    "            self.bns.append(BatchNorm(hidden_channels))\n",
    "        # Testa finale: MLP (non convoluzionale)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(hidden_channels, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_channels, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        for conv, bn in zip(self.convs, self.bns):\n",
    "            x = conv(x, edge_index)\n",
    "            x = F.relu(bn(x))\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "# Esempio di istanziazione del modello\n",
    "# Puoi cambiare num_layers e dropout a piacere\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "model = StripGCN(in_channels=1, hidden_channels=16*8, num_layers=4, dropout=0.3).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "# Calcola il peso per la classe positiva (cluster)\n",
    "all_train_labels = np.concatenate([data.y.cpu().numpy() for data in train_graphs])\n",
    "n_pos = (all_train_labels == 1).sum()\n",
    "n_neg = (all_train_labels == 0).sum()\n",
    "pos_weight = torch.tensor([np.sqrt(n_neg / n_pos)], dtype=torch.float32).to(device)\n",
    "print(f\"pos_weight for BCEWithLogitsLoss: {pos_weight.item():.2f}\")\n",
    "\n",
    "# Loss pesata\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "5cbb5caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, epoch, path):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "    }, path)\n",
    "\n",
    "def save_model(model, path):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "def load_model(model, optimizer, checkpoint_path, load_checkpoint=True):\n",
    "    if load_checkpoint and os.path.exists(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        if optimizer is not None and 'optimizer_state_dict' in checkpoint:\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        print(f\"Checkpoint loaded from {checkpoint_path}\")\n",
    "    else:\n",
    "        print(\"No checkpoint loaded.\")\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "5e7f4b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoint loaded.\n"
     ]
    }
   ],
   "source": [
    "# Parametro per decidere se caricare il checkpoint\n",
    "LOAD_CHECKPOINT = False\n",
    "checkpoint_path = \"gnn_model/checkpoint.pt\"\n",
    "model_path = \"gnn_model/model.pt\"\n",
    "\n",
    "model, optimizer = load_model(model, optimizer, checkpoint_path, load_checkpoint=LOAD_CHECKPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "4ec5a84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_metrics(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            out = model(batch)\n",
    "            preds = (out.squeeze() > 0.5).cpu().numpy()\n",
    "            labels = batch.y.cpu().numpy()\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(labels)\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    prec = precision_score(all_labels, all_preds, average='binary', zero_division=0)\n",
    "    rec = recall_score(all_labels, all_preds, average='binary', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='binary', zero_division=0)\n",
    "    return acc, prec, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "6cc908d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Train loss: 6.7921E-02 - Val loss: 1.6312E-02 - Time: 3.51s\n",
      "Epoch 2/10 - Train loss: 1.9613E-02 - Val loss: 1.2030E-02 - Time: 3.47s\n",
      "Epoch 3/10 - Train loss: 1.9066E-02 - Val loss: 1.0796E-02 - Time: 3.44s\n",
      "Epoch 4/10 - Train loss: 1.9490E-02 - Val loss: 1.0606E-02 - Time: 3.42s\n",
      "Epoch 5/10 - Train loss: 1.8463E-02 - Val loss: 1.0540E-02 - Time: 3.41s\n",
      "Epoch 6/10 - Train loss: 1.7538E-02 - Val loss: 1.3250E-02 - Time: 3.42s\n",
      "Epoch 7/10 - Train loss: 1.8356E-02 - Val loss: 1.1474E-02 - Time: 3.42s\n",
      "Epoch 8/10 - Train loss: 1.7736E-02 - Val loss: 1.0705E-02 - Time: 3.41s\n",
      "Epoch 9/10 - Train loss: 1.7678E-02 - Val loss: 1.0941E-02 - Time: 3.44s\n",
      "Epoch 10/10 - Train loss: 1.7136E-02 - Val loss: 9.9355E-03 - Time: 3.43s\n",
      "Modello finale salvato in gnn_model/model.pt\n",
      "Test accuracy: 99.65%\n",
      "Val metrics - Acc: 0.998 Prec: 0.570 Rec: 0.986 F1: 0.722\n",
      "Test metrics - Acc: 0.997 Prec: 0.546 Rec: 0.980 F1: 0.701\n"
     ]
    }
   ],
   "source": [
    "# Training loop con salvataggio checkpoint\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_train_samples = 0\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        out = model(batch).squeeze(-1)\n",
    "        target = batch.y.float()\n",
    "        loss = loss_fn(out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        total_loss += loss.item() * batch.y.size(0)\n",
    "        total_train_samples += batch.y.size(0)\n",
    "    avg_train_loss = total_loss / total_train_samples\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    # Validation loss\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    total_val_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = batch.to(device)\n",
    "            out = model(batch).squeeze(-1)\n",
    "            loss = loss_fn(out, batch.y.float())\n",
    "            val_loss += loss.item() * batch.y.size(0)\n",
    "            total_val_samples += batch.y.size(0)\n",
    "    avg_val_loss = val_loss / total_val_samples\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Train loss: {avg_train_loss:.4E} - Val loss: {avg_val_loss:.4E} - Time: {elapsed:.2f}s\")\n",
    "    # Salva checkpoint ad ogni epoca\n",
    "    save_checkpoint(model, optimizer, epoch, checkpoint_path)\n",
    "\n",
    "# Salva il modello finale\n",
    "save_model(model, model_path)\n",
    "print(f\"Modello finale salvato in {model_path}\")\n",
    "\n",
    "# Test accuracy\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        batch = batch.to(device)\n",
    "        out = model(batch).squeeze(-1)\n",
    "        pred = (torch.sigmoid(out) > 0.5).cpu().numpy()\n",
    "        labels = batch.y.cpu().numpy()\n",
    "        correct += (pred == labels).sum()\n",
    "        total += labels.size\n",
    "print(f\"Test accuracy: {correct/total:.2%}\")\n",
    "\n",
    "val_acc, val_prec, val_rec, val_f1 = evaluate_metrics(model, val_loader, device)\n",
    "print(f\"Val metrics - Acc: {val_acc:.3f} Prec: {val_prec:.3f} Rec: {val_rec:.3f} F1: {val_f1:.3f}\")\n",
    "\n",
    "test_acc, test_prec, test_rec, test_f1 = evaluate_metrics(model, test_loader, device)\n",
    "print(f\"Test metrics - Acc: {test_acc:.3f} Prec: {test_prec:.3f} Rec: {test_rec:.3f} F1: {test_f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "f2676409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvati i primi 20 plot in 'images/mimega'\n"
     ]
    }
   ],
   "source": [
    "# --- Plot dei primi 20 esempi dal test_loader ---\n",
    "os.makedirs(\"images/mimega\", exist_ok=True)\n",
    "model.eval()\n",
    "count = 0\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        batch = batch.to(device)\n",
    "        for i in range(batch.num_graphs):\n",
    "            data = batch[i]\n",
    "            charges = data.x.cpu().numpy().flatten()\n",
    "            labels_true = data.y.cpu().numpy()\n",
    "            pred = model(data)\n",
    "            pred_labels = (torch.sigmoid(pred).squeeze(-1).cpu().numpy() > 0.5).astype(int)\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.subplot(2, 1, 1)\n",
    "            plt.bar(np.arange(len(charges)), charges, color='gray', alpha=0.7)\n",
    "            plt.title('Carica su ciascuna delle 360 strip (evento di test)')\n",
    "            plt.xlabel('Strip')\n",
    "            plt.ylabel('Carica')\n",
    "            plt.subplot(2, 1, 2)\n",
    "            plt.plot(labels_true, label='Label ricostruite (algoritmo)', drawstyle='steps-mid')\n",
    "            plt.plot(pred_labels, label='Predizione modello', drawstyle='steps-mid', alpha=0.7)\n",
    "            plt.xlabel('Strip')\n",
    "            plt.ylabel('Cluster label')\n",
    "            plt.legend()\n",
    "            plt.title('Confronto: label ricostruite vs predizione modello')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"images/mimega/test_example_{count+1}.png\")\n",
    "            plt.close()\n",
    "            count += 1\n",
    "            if count >= 20:\n",
    "                break\n",
    "        if count >= 20:\n",
    "            break\n",
    "print(\"Salvati i primi 20 plot in 'images/mimega'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f03f29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
