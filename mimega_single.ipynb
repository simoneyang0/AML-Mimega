{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cfea0bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv, BatchNorm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1b11afc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PARAMETRI DI CLUSTERING\n",
    "# =============================================================================\n",
    "CLUSTER_PARAMS = dict(\n",
    "    charge_threshold=750,\n",
    "    min_consecutive_strips=2,\n",
    "    max_gap=2,\n",
    "    max_cluster_size=15,\n",
    "    max_internal_gap=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6623fa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# FUNZIONI DI CLUSTERING\n",
    "# =============================================================================\n",
    "\n",
    "def cluster_strips_with_charges(event, params):\n",
    "    \"\"\"Identifica cluster consecutivi di strip con carica sopra soglia.\"\"\"\n",
    "    clusters = []\n",
    "    charges = []\n",
    "    current_cluster = []\n",
    "    current_charges = []\n",
    "    previous_index = None\n",
    "\n",
    "    for strip_index, charge in enumerate(event):\n",
    "        if charge >= params['charge_threshold']:\n",
    "            if previous_index is not None and strip_index - previous_index - 1 >= params['max_gap']:\n",
    "                if params['min_consecutive_strips'] <= len(current_cluster) < params['max_cluster_size']:\n",
    "                    n_gaps = (max(current_cluster) - min(current_cluster) + 1) - len(current_cluster)\n",
    "                    if n_gaps <= params['max_internal_gap']:\n",
    "                        clusters.append(current_cluster)\n",
    "                        charges.append(current_charges)\n",
    "                current_cluster, current_charges = [], []\n",
    "            current_cluster.append(strip_index)\n",
    "            current_charges.append(charge)\n",
    "            previous_index = strip_index\n",
    "\n",
    "    # Aggiungi ultimo cluster se valido\n",
    "    if params['min_consecutive_strips'] <= len(current_cluster) < params['max_cluster_size']:\n",
    "        n_gaps = (max(current_cluster) - min(current_cluster) + 1) - len(current_cluster)\n",
    "        if n_gaps <= params['max_internal_gap']:\n",
    "            clusters.append(current_cluster)\n",
    "            charges.append(current_charges)\n",
    "\n",
    "    return clusters, charges\n",
    "\n",
    "def assign_labels(event, params):\n",
    "    \"\"\"Assegna etichetta 1 alle strip che fanno parte di un cluster valido.\"\"\"\n",
    "    labels = np.zeros(len(event), dtype=int)\n",
    "    clusters, _ = cluster_strips_with_charges(event, params)\n",
    "    for cluster in clusters:\n",
    "        for idx in range(min(cluster), max(cluster) + 1):\n",
    "            labels[idx] = 1\n",
    "    return labels, len(clusters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "372813f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di cluster trovati in X: 908\n",
      "Numero di cluster trovati in Y: 3047\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# CARICAMENTO DATI E LABELING\n",
    "# =============================================================================\n",
    "\n",
    "x_events = np.load('data/mimega/signal_x.npy', allow_pickle=True)\n",
    "y_events = np.load('data/mimega/signal_y.npy', allow_pickle=True)\n",
    "\n",
    "x_labels, y_labels = [], []\n",
    "n_x_clusters = n_y_clusters = 0\n",
    "\n",
    "for x_ev, y_ev in zip(x_events, y_events):\n",
    "    x_lab, n_x = assign_labels(x_ev, CLUSTER_PARAMS)\n",
    "    y_lab, n_y = assign_labels(y_ev, CLUSTER_PARAMS)\n",
    "    x_labels.append(x_lab)\n",
    "    y_labels.append(y_lab)\n",
    "    n_x_clusters += n_x\n",
    "    n_y_clusters += n_y\n",
    "\n",
    "print(f\"Numero di cluster trovati in X: {n_x_clusters}\")\n",
    "print(f\"Numero di cluster trovati in Y: {n_y_clusters}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d5827e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# CREAZIONE DEI GRAFICI\n",
    "# =============================================================================\n",
    "\n",
    "def events_to_graphs(events, labels):\n",
    "    \"\"\"Trasforma eventi e label in grafi PyG per la GNN.\"\"\"\n",
    "    data_list = []\n",
    "    for event, label in zip(events, labels):\n",
    "        event = np.array(event, dtype=np.float32)\n",
    "        label = np.array(label, dtype=np.int64)\n",
    "        x = torch.tensor(event, dtype=torch.float).unsqueeze(1)\n",
    "        y = torch.tensor(label, dtype=torch.long)\n",
    "        N = x.shape[0]\n",
    "        edge_index = torch.tensor(\n",
    "            [[i, i+1] for i in range(N-1)] + [[i+1, i] for i in range(N-1)],\n",
    "            dtype=torch.long\n",
    "        ).t().contiguous()\n",
    "        data_list.append(Data(x=x, edge_index=edge_index, y=y))\n",
    "    return data_list\n",
    "\n",
    "# Split train/val/test\n",
    "all_events = np.concatenate([x_events, y_events])\n",
    "all_labels = np.concatenate([x_labels, y_labels])\n",
    "all_data = list(zip(all_events, all_labels))\n",
    "\n",
    "train_data, temp_data = train_test_split(all_data, test_size=0.3, random_state=42)\n",
    "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
    "\n",
    "train_events, train_labels = zip(*train_data)\n",
    "val_events, val_labels = zip(*val_data)\n",
    "test_events, test_labels = zip(*test_data)\n",
    "\n",
    "train_graphs = events_to_graphs(train_events, train_labels)\n",
    "val_graphs = events_to_graphs(val_events, val_labels)\n",
    "test_graphs = events_to_graphs(test_events, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_graphs, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_graphs, batch_size=32)\n",
    "test_loader = DataLoader(test_graphs, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fa7a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# DEFINIZIONE MODELLO GNN\n",
    "# =============================================================================\n",
    "\n",
    "class GNN(nn.Module):\n",
    "    \"\"\"Modello GCN per classificazione strip-wise.\"\"\"\n",
    "    def __init__(self, in_channels=1, hidden_channels=32, num_layers=3, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.convs = nn.ModuleList([GCNConv(in_channels, hidden_channels)])\n",
    "        self.bns = nn.ModuleList([BatchNorm(hidden_channels)])\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.convs.append(GCNConv(hidden_channels, hidden_channels))\n",
    "            self.bns.append(BatchNorm(hidden_channels))\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(hidden_channels, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_channels, 1)\n",
    "        )\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        for conv, bn in zip(self.convs, self.bns):\n",
    "            x = F.relu(bn(conv(x, edge_index)))\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        return self.head(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735352aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "pos_weight for BCEWithLogitsLoss: 16.82\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# INIZIALIZZAZIONE E LOSS\n",
    "# =============================================================================\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = GNN(in_channels=1, hidden_channels=128, num_layers=4, dropout=0.3).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "pos_weight = torch.tensor([6], dtype=torch.float32).to(device)\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight = pos_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a0d7cde2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nessun checkpoint caricato.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# SALVATAGGIO E CARICAMENTO MODELLO\n",
    "# =============================================================================\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch, path):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "    }, path)\n",
    "\n",
    "def save_model(model, path):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"Modello finale salvato in {path}\")\n",
    "\n",
    "def load_model(model, optimizer, checkpoint_path, load_checkpoint=True):\n",
    "    if load_checkpoint and os.path.exists(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        if optimizer and 'optimizer_state_dict' in checkpoint:\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint.get('epoch', 0) + 1\n",
    "        print(f\"Checkpoint caricato da {checkpoint_path}, riprendo da epoch {start_epoch}\")\n",
    "    else:\n",
    "        print(\"Nessun checkpoint caricato.\")\n",
    "        start_epoch = 0\n",
    "    return model, optimizer, start_epoch\n",
    "\n",
    "checkpoint_path = \"gnn_model/mimega/checkpoint.pt\"\n",
    "model_path = \"gnn_model/mimega/model.pt\"\n",
    "model, optimizer, start_epoch = load_model(model, optimizer, checkpoint_path, load_checkpoint=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e36a519b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Train loss: 0.0551 - Validation loss: 0.0081 - Time: 3.89s\n",
      "Epoch 2/20 - Train loss: 0.0124 - Validation loss: 0.0078 - Time: 3.90s\n",
      "Epoch 3/20 - Train loss: 0.0122 - Validation loss: 0.0086 - Time: 3.98s\n",
      "Epoch 4/20 - Train loss: 0.0122 - Validation loss: 0.0085 - Time: 4.05s\n",
      "Epoch 5/20 - Train loss: 0.0110 - Validation loss: 0.0071 - Time: 4.13s\n",
      "Epoch 6/20 - Train loss: 0.0115 - Validation loss: 0.0071 - Time: 3.81s\n",
      "Epoch 7/20 - Train loss: 0.0112 - Validation loss: 0.0071 - Time: 3.68s\n",
      "Epoch 8/20 - Train loss: 0.0111 - Validation loss: 0.0094 - Time: 3.80s\n",
      "Epoch 9/20 - Train loss: 0.0112 - Validation loss: 0.0094 - Time: 3.73s\n",
      "Epoch 10/20 - Train loss: 0.0115 - Validation loss: 0.0067 - Time: 3.89s\n",
      "Epoch 11/20 - Train loss: 0.0109 - Validation loss: 0.0073 - Time: 4.01s\n",
      "Epoch 12/20 - Train loss: 0.0110 - Validation loss: 0.0067 - Time: 3.90s\n",
      "Epoch 13/20 - Train loss: 0.0109 - Validation loss: 0.0067 - Time: 4.01s\n",
      "Epoch 14/20 - Train loss: 0.0111 - Validation loss: 0.0101 - Time: 4.05s\n",
      "Epoch 15/20 - Train loss: 0.0107 - Validation loss: 0.0079 - Time: 3.90s\n",
      "Epoch 16/20 - Train loss: 0.0109 - Validation loss: 0.0071 - Time: 4.10s\n",
      "Epoch 17/20 - Train loss: 0.0111 - Validation loss: 0.0067 - Time: 4.06s\n",
      "Epoch 18/20 - Train loss: 0.0111 - Validation loss: 0.0078 - Time: 4.07s\n",
      "Epoch 19/20 - Train loss: 0.0112 - Validation loss: 0.0077 - Time: 3.90s\n",
      "Epoch 20/20 - Train loss: 0.0110 - Validation loss: 0.0074 - Time: 3.96s\n",
      "Training completo.\n",
      "Modello finale salvato in gnn_model/mimega/model.pt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# TRAINING\n",
    "# =============================================================================\n",
    "\n",
    "epochs = 20\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_samples = 0\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        output = model(batch).squeeze(-1)\n",
    "        loss = loss_fn(output, batch.y.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        total_loss += loss.item() * batch.y.size(0)\n",
    "        total_samples += batch.y.size(0)\n",
    "    train_loss = total_loss / total_samples\n",
    "\n",
    "    model.eval()\n",
    "    val_loss, val_samples = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = batch.to(device)\n",
    "            output = model(batch).squeeze(-1)\n",
    "            loss = loss_fn(output, batch.y.float())\n",
    "            val_loss += loss.item() * batch.y.size(0)\n",
    "            val_samples += batch.y.size(0)\n",
    "    val_loss /= val_samples\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Train loss: {train_loss:.4f} - Validation loss: {val_loss:.4f} - Time: {time.time()-start:.2f}s\")\n",
    "    save_checkpoint(model, optimizer, epoch, checkpoint_path)\n",
    "\n",
    "\n",
    "print(\"Training completo.\")\n",
    "save_model(model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fc0425c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 99.75%\n",
      "Val metrics - Acc: 0.999 Prec: 0.706 Rec: 0.935 F1: 0.805\n",
      "Test metrics - Acc: 0.998 Prec: 0.662 Rec: 0.930 F1: 0.773\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# VALUTAZIONE DEL MODELLO\n",
    "# =============================================================================\n",
    "\n",
    "def evaluate_metrics(model, loader, device):\n",
    "    model.eval()\n",
    "    preds, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            output = model(batch).squeeze()\n",
    "            preds.append((output > 0.5).cpu().numpy())\n",
    "            labels.append(batch.y.cpu().numpy())\n",
    "    preds = np.concatenate(preds)\n",
    "    labels = np.concatenate(labels)\n",
    "    return (\n",
    "        accuracy_score(labels, preds),\n",
    "        precision_score(labels, preds, zero_division=0),\n",
    "        recall_score(labels, preds, zero_division=0),\n",
    "        f1_score(labels, preds, zero_division=0)\n",
    "    )\n",
    "\n",
    "test_acc = (sum(\n",
    "    ((torch.sigmoid(model(batch.to(device)).squeeze()) > 0.5).cpu().numpy() == batch.y.cpu().numpy()).sum()\n",
    "    for batch in test_loader\n",
    "), sum(len(batch.y) for batch in test_loader))\n",
    "print(f\"Test accuracy: {test_acc[0]/test_acc[1]:.2%}\")\n",
    "\n",
    "val_acc, val_prec, val_rec, val_f1 = evaluate_metrics(model, val_loader, device)\n",
    "print(f\"Val metrics - Acc: {val_acc:.3f} Prec: {val_prec:.3f} Rec: {val_rec:.3f} F1: {val_f1:.3f}\")\n",
    "\n",
    "test_acc, test_prec, test_rec, test_f1 = evaluate_metrics(model, test_loader, device)\n",
    "print(f\"Test metrics - Acc: {test_acc:.3f} Prec: {test_prec:.3f} Rec: {test_rec:.3f} F1: {test_f1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8c5d4cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvati i primi 20 plot in 'images/mimega'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# VISUALIZZAZIONE RISULTATI SU 20 EVENTI\n",
    "# =============================================================================\n",
    "\n",
    "os.makedirs(\"images/mimega\", exist_ok=True)\n",
    "model.eval()\n",
    "count = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        batch = batch.to(device)\n",
    "        for i in range(batch.num_graphs):\n",
    "            data = batch[i]\n",
    "            charges = data.x.cpu().numpy().flatten()\n",
    "            true_labels = data.y.cpu().numpy()\n",
    "            pred_labels = (torch.sigmoid(model(data)).squeeze().cpu().numpy() > 0.5).astype(int)\n",
    "\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.subplot(2, 1, 1)\n",
    "            plt.bar(np.arange(len(charges)), charges, color='gray', alpha=0.7)\n",
    "            plt.title('Carica per strip (test event)')\n",
    "            plt.xlabel('Strip')\n",
    "            plt.ylabel('Carica')\n",
    "\n",
    "            plt.subplot(2, 1, 2)\n",
    "            plt.plot(true_labels, label='Label ricostruite', drawstyle='steps-mid')\n",
    "            plt.plot(pred_labels, label='Predizione modello', drawstyle='steps-mid', alpha=0.7)\n",
    "            plt.xlabel('Strip')\n",
    "            plt.ylabel('Cluster')\n",
    "            plt.legend()\n",
    "            plt.title('Confronto: Ricostruito vs Predetto')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"images/mimega/test_example_{count+1}.png\")\n",
    "            plt.close()\n",
    "            count += 1\n",
    "            if count >= 20:\n",
    "                break\n",
    "        if count >= 20:\n",
    "            break\n",
    "\n",
    "print(\"Salvati i primi 20 plot in 'images/mimega'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
